{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A one-stop hub for all your DevOps documentation needs, containing helpful guides, how-to tutorials, and top-notch best practices.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Monitoring</li> </ul> <p>Your go-to source for DevOps monitoring expertise, offering insights, tools, and techniques to keep a vigilant eye on your systems and applications.</p> <ul> <li>Logging</li> </ul> <p>Unlock the power of DevOps logging with our repository, packed with insights, tutorials, and solutions to help you capture, analyze, and make sense of your application logs    </p>"},{"location":"Bash/bash/","title":"Bash","text":""},{"location":"Bash/bash/#section-11-hello-world","title":"Section 1.1: Hello World","text":""},{"location":"Bash/bash/#interactive-shell","title":"Interactive Shell","text":"<p>The Bash shell is commonly used interactively:It lets you enter and edit commands, then executes them when you press the Return key.    </p> <p>Output \"Hello World\" by typing the following </p> <pre><code>    echo \"Hello World\"\n    #&gt; Hello  World # Output Example \n</code></pre> <p>Notes</p> <ul> <li>You can change the shell by just typing the name of the shell in terminal. For example: sh,bash etc. </li> <li>echo is a bash built-in command that writes the arguments it receives to the standard output. </li> </ul>"},{"location":"Bash/bash/#non-interactive-shell","title":"Non-Interactive Shell","text":"<p>The Bash shell can also be run non-interactively from a script, making the shell require no human interaction. </p> <p>Follow these steps to create a Hello World script:</p> <pre><code>1. Create a new file called hello-world.sh\n    touch hello-world.sh\n2. Make the script executable bu running \n    chmod +x hello-world.sh\n3. Add this code \n    #!/bin/bash\n    echo \"Hello World\"\n</code></pre> <p>Line 1: The first line of the scriptmust start with the character sequence #!, referred to as sshebang1. It instructs the operating ssytem to run /bin/bash, passinf it th scipt's path as an arguments. Line 2: Uses the echo command to write Hello World to the standart output.</p> <pre><code>4. Execture the hello-world.sh script from the command line using one of the following.\n    - ./hello-world.sh \u2013 most commonly used, and recommended\n    - bin/bash hello-world.sh\n    - bash hello-world.sh \u2013 assuming /bin is in your $PATH\n    - sh hello-world.sh\n</code></pre>"},{"location":"Bash/bash/#section-12-hello-world-using-variables","title":"Section 1.2: Hello World Using Variables","text":"<p>Create a new file called hello.sh with the following content and gice it executable permissions with the chmod +x hello.sh</p> <pre><code>Execute/Run via: ./hello.sh\n\n#!/usr/bin/env bash\n# Note that spaces cannot be used around the `=` assignment operator\nwhom_variable=\"World\"\n# Use printf to safely output the data\nprintf \"Hello, %s\\n\" \"$whom_variable\"\n#&gt; Hello, World\n</code></pre> <p>This will print Hello, World to standard output when executed.</p> <p>The following code accepts an argument $1, which is the \ufb01rst command line argument, and outputs it in a formatted string, following Hello,.</p> <pre><code>Execute/Run via: ./hello.sh World\n#!/usr/bin/env bash\nprintf \"Hello, %s\\n\" \"$1\"\n#&gt; Hello, World\n</code></pre> <p>It is important to note that $1 has to be quoted in double quote, not single quote. \"$1\" expands to the \ufb01rst command line argument, as desired, while '$1' evaluates to literal string $1.</p>"},{"location":"Logging/kafka/","title":"KAFKA","text":"<p>Introduction</p> <p>Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.</p> <p>Why Kafka? Benefits and Use Cases</p> <ul> <li>Data Integration</li> <li>Metrics and Monitoring</li> <li>Log Aggregation</li> <li>Stream Processing</li> <li>Publish-Subscribe Messaging</li> <li>Kafka Architecture \u2013 Fundamental Concepts</li> <li>Kafka Topics</li> <li>Kafka Partitioning</li> </ul> <p>How Kafka Partitioning Works</p> <p></p> <ul> <li>Kafka Brokers      Kafka brokers are like computer workers in the Kafka system. They store and handle events, manage data partitions, and work together for reliability. Think of them as the backbone of Kafka.     So, brokers are the worker bees of the Kafka system, managing events and making sure everything runs smoothly.</li> </ul> <p>Replications</p> <pre><code>- To ensure data safety, Kafka creates copies of data partitions called leader and follower replicas. When you write data, it goes to the leader, and then both leader and followers automatically replicate the data. If a node fails, another takes over. As a developer, you don't need to worry much about this process. Just know your data is secure and resilient.\nClient Applications \n- In Kafka, there are two main types of client applications: producers and consumers. Producers put messages into topics, while consumers read messages from topics. These are the building blocks for working with Kafka. Everything that's not a Kafka broker is essentially a producer or consumer, or both. They're how you connect and work with a Kafka cluster       \nKafka Producers\n- The API surface of the producer library is fairly lightweight: In Java, there is a class called KafkaProducer that you use to connect to the cluster. \nKafka Consumers\n- Using the consumer API is similar in principle to the producer. You use a class called KafkaConsumer to connect to the cluster (passing a configuration map to specify the address of the cluster, security, and other parameters).\n</code></pre> <p>Kafka Installation</p> <pre><code>Prerequisite: Java 11 or 17 should be installed on the system\nhttps://kafka.apache.org/documentation.html#java\n</code></pre> <p></p> <p>Download Apache Kafka</p> <pre><code>https://kafka.apache.org/downloads\n</code></pre> <ul> <li>Extract or untar the downloaded kafka file</li> </ul> <pre><code>tar xzvf kafka_2.12-3.5.1.tgz\n</code></pre> <p></p> <ul> <li>Now test Kafka and move the the kafka directory and use the below command    </li> </ul> <pre><code>bin/kafka-topic.sh\n</code></pre> <p></p> <ul> <li>Setting the Path </li> </ul> <pre><code>Open '.bashrc' file using the command: \nvi .bashrc\n</code></pre> <p></p> <ul> <li>Move to the end and set the path using the command</li> </ul> <pre><code>export PATH=/home/rajivgs/Downloads/webi/kafka_2.12-3.5.1/bin:$PATH\n</code></pre> <p></p> <ul> <li>To test, run the command from and directory.</li> </ul> <pre><code>kafka-topic.sh\n</code></pre> <p></p> <p>If the below output is shown, it means the path is successfully set. If not, something is wrong.</p> <ul> <li>Starting Zookeeper Server on Linux</li> </ul> <pre><code>To start zookeeper, there are following below steps used\n\nStep 1: Move to the and create a new directory 'data'\n\nStep 2: Again, move to the data directory, and make two new directories as 'zookeeper' and 'kafka'.\n</code></pre> <p></p> <p>To run the zookeeper server. Open the zookeeper.properties file, which is located under the config folder. </p> <pre><code> vi config/zookeeper.properties\n</code></pre> <p>Edit the value of dataDIr by placing the path of the newly created zookeeper folder.</p> <pre><code> dataDir=/home/rajivgs/Downloads/webi/kafka_2.12-3.5.1/data/zookeeper\n\n zookeeper-server-start.sh config/zookeeper.properties \n</code></pre> <p></p> <pre><code>zookeeper-server-start.sh config/zookeeper.properties\n</code></pre> <p></p> <p>Move to the 'config' folder, and open server.properties file.</p> <pre><code>vi config/server.properties\n</code></pre> <pre><code>Edit the value of logs.dir=/path/data/kafka as shown below\n</code></pre> <p></p> <p>Now, run the Kafka server by using the following command:</p> <pre><code>  kafka-server-start.sh config/server.properties\n</code></pre> <p></p> <p>Creating Kafka Topics Initially, make sure that both zookeeper, as well as the Kafka server, should be started.</p> <pre><code>kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic-name  ||\nkafka-topics.sh --bootstrap-server localhost:9092 --create --topic logger --partitions 1 --replication-factor 1\n</code></pre> <p></p> <p>Here's a breakdown of the command in short points:</p> <ul> <li> <p><code>kafka-topics.sh</code>: This is the Kafka command-line tool used to manage Kafka topics.</p> </li> <li> <p><code>--bootstrap-server localhost:9092</code>: Specifies the Kafka broker(s) to connect to. In this case, it's connecting to a Kafka broker running locally on port 9092.</p> </li> <li> <p><code>--create</code>: Indicates that you want to create a new Kafka topic.</p> </li> <li> <p><code>--topic logger</code>: Specifies the name of the topic to be created, in this case, the topic name is \"logger\".</p> </li> <li> <p><code>--partitions 1</code>: Specifies the number of partitions for the topic. Partitions are the units of parallelism in Kafka. Here, you're creating the topic with 1 partition.</p> </li> <li> <p><code>--replication-factor 1</code>: Sets the replication factor for the topic. Replication ensures data durability and availability. Here, you're using a replication factor of 1, meaning there's only one copy of each partition's data.</p> </li> </ul> <p>So, the command is creating a Kafka topic named \"logger\" with a single partition and a replication factor of 1, connecting to a Kafka broker running on localhost at port 9092.</p> <p>Listing the number of Topics</p> <pre><code>kafka-topics.sh --bootstrap-server localhost:9092 --list\n</code></pre> <ul> <li>Describing the topic</li> </ul> <pre><code>kafka-topics.sh --bootstrap-server localhost:9092 -describe --topic topic-name \nkafka-topics.sh --bootstrap-server kafka2.rajivgopalsingh.com.np:9092 -describe --topic logger-01 \n</code></pre> <ul> <li>Deleting the topic</li> </ul> <pre><code>kafka-topics.sh --bootstrap-server localhost:9092  --topic topic-name  -delete \nkafka-topics.sh --bootstrap-server kafka2.rajivgopalsingh.com.np:9092  --topic logger-01  -delete \n</code></pre> <ul> <li>Kafka Console Producer</li> </ul> <pre><code>kafka-console-producer.sh --broker-list localhost:9092 --topic topic-name\n</code></pre> <ul> <li>Kafka Console Consumer</li> </ul> <pre><code>kafka-console-consumerr.sh --broker-list localhost:9092 --topic topic-name  ||\nkafka-console-producer.sh --broker-list localhost:9092 --topic topic-name --from-beginning \n</code></pre> <p>Practice:</p> <pre><code>1. https://kube-logging.dev/docs/examples/kafka-nginx/\n</code></pre>"},{"location":"Monitoring/1.%20setup_prometheus-grafana/","title":"Setup the Prometheus and Grafana","text":""},{"location":"Monitoring/1.%20setup_prometheus-grafana/#prometheus-setup","title":"Prometheus Setup","text":"<ul> <li>Prometheus Installation</li> </ul> <pre><code> helm repo add prometheus-community https://prometheus-community.github.io/helm-charts            \n helm repo update                                                                                 \n helm install name prometheus-community/prometheus --namespace namepsace-name                     \n</code></pre> <ul> <li>Check the status of the pods. Check the promethues server by doing the port forward </li> </ul> <pre><code> kubectl port-forward svc/svc_name -n namespace-name localhost-port:pod-port        \n kubectl port-forward svc/prometheus-operated -n zerone-monitoring 9090:9090                      \n</code></pre>"},{"location":"Monitoring/1.%20setup_prometheus-grafana/#setup-the-grafana","title":"Setup the Grafana","text":"<ul> <li>Grafana Installation</li> </ul> <pre><code> helm repo add grafana https://grafana.github.io/helm-charts                                      \n helm repo update                                                                                 \n helm install name grafana/grafana  --namespace namespace-name                                    \n</code></pre> <ul> <li>Get the password of the grafana</li> </ul> <pre><code> kubectl  get secret grafana -n zerone-monitoring\n echo \u201cpassword_value\u201d  openssl base64 -d ; echo                                                 \n echo \u201cusername_value\u201d  openssl base64 -d ; echo \n kubectl port-forward svc/grafana -n zerone-monitoring 3000:3000 \n</code></pre> <ul> <li>Add the prometheus in the grafana dashboard.</li> </ul> <pre><code>Prometheus server URL:  http://prometheus-operated:9090\nhttp://service-name:port\n</code></pre>"},{"location":"Monitoring/1.%20setup_prometheus-grafana/#conclusion-after-setting-up-prometheus-and-grafana","title":"Conclusion After Setting Up Prometheus and Grafana","text":"<p>Setting up Prometheus and Grafana is a powerful combination for monitoring and visualizing your infrastructure and applications. After completing the setup, you can draw several conclusions and benefits:</p> <ol> <li> <p>Real-time Monitoring: With Prometheus, you have a powerful monitoring system that collects and stores metrics in real-time. This allows you to keep a close eye on the health and performance of your systems.</p> </li> <li> <p>Alerting: Prometheus provides alerting capabilities, allowing you to set up alerts based on predefined thresholds. You can be notified of issues before they become critical, helping you maintain system reliability.</p> </li> <li> <p>Historical Data: Prometheus stores historical metric data, enabling you to analyze trends and identify long-term performance patterns. This data can be invaluable for capacity planning and troubleshooting.</p> </li> <li> <p>Custom Metrics: You can instrument your applications and services to expose custom metrics, giving you deep insights into the specific aspects of your software that matter most to you.</p> </li> <li> <p>Grafana Dashboards: Grafana offers a user-friendly interface for creating and customizing dashboards that visualize Prometheus data. These dashboards can provide at-a-glance information about the state of your systems.</p> </li> <li> <p>Data Correlation: Grafana allows you to correlate data from multiple sources and display them in a single dashboard. This helps in diagnosing complex issues that involve multiple components.</p> </li> <li> <p>Flexibility: Both Prometheus and Grafana are highly customizable. You can adapt them to suit your unique monitoring needs, whether you're running a small web application or a large-scale distributed system.</p> </li> <li> <p>Community Support: Prometheus and Grafana have vibrant communities with active development and extensive documentation. You can find plugins, extensions, and support readily available online.</p> </li> <li> <p>Open Source: Both Prometheus and Grafana are open-source projects, meaning you can use them without incurring licensing costs. This makes them an economical choice for monitoring your infrastructure.</p> </li> <li> <p>Scalability: These tools are designed to scale horizontally, so you can expand your monitoring as your infrastructure grows.</p> </li> <li> <p>Integration: Prometheus and Grafana can integrate with various other tools and services, allowing you to centralize your monitoring and combine it with other aspects of your DevOps stack.</p> </li> </ol> <p>In conclusion, setting up Prometheus and Grafana provides you with a robust monitoring and visualization solution that empowers you to maintain the health and performance of your systems, make data-driven decisions, and respond proactively to issues. It's a valuable addition to any organization's infrastructure management toolkit. However, to maximize its benefits, ongoing maintenance and tuning may be required to ensure it continues to meet your evolving monitoring needs.</p>"},{"location":"Monitoring/2.%20gmail_integration/","title":"Gmail Integration","text":"<p>Description</p> <p>The application provides a Webhook integration for Prometheus AlertManager to push alerts to Google Chat rooms.</p> <ul> <li>Prometheus Installation</li> </ul> <pre><code> helm repo add prometheus-community https://prometheus-community.github.io/helm-charts            \n helm repo update                                                                                 \n helm install name prometheus-community/prometheus --namespace namepsace-name    \n</code></pre> <ul> <li> <p>Alertmanager-gchat-integration</p> <p>A web application which listens for Prometheus AlertManager alerts' and forward them to Google  Chat rooms.</p> </li> </ul> <pre><code> Install gchat manager using helm chart     \n helm repo add julb https://charts.julb.me \n helm install name julb/alertmanager-gchat-integration  --namespace namespace-name\n</code></pre> <ul> <li>Add the Gmail Webook in the prometheus-community-alertmanager</li> </ul> <pre><code>url : \u2018http://service.name(gchat-integration).namespace/alerts?room=lotus(roomname)\u2019\napiVersion: v1\ndata:\n  alertmanager.yml: |\n    global:\n      resolve_timeout: 1m\n    route:\n      group_by: ['alertname']\n      group_wait: 10s\n      group_interval: 10s\n      repeat_interval: 1h\n      receiver: 'gmail'\n    receivers:\n    - name: 'gmail'\n      webhook_configs:\n      - url: 'http://alert-manager-alertmanager-gchat-integration.zerone-monitoring/alerts?room=lotus'\n    templates:\n    - /etc/alertmanager/*.tmpl\nkind: ConfigMap\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"v1\",\"data\":{\"alertmanager.yml\":\"global:\\n  resolve_timeout: 1m\\nroute:\\n  group_by: ['alertname']\\n  group_wait: 10s\\n  group_interval: 10s\\n  repeat_interval: 1h\\n  receiver: 'asd'\\nreceivers:\\n- name: 'asd'\\n  webhook_configs:\\n  - url: 'http://alert-manager-alertmanager-gchat-integration.zerone-monitoring.svc/alerts?room=lotus'\\ntemplates:\\n- /etc/alertmanager/*.tmpl\\n\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{\"meta.helm.sh/release-name\":\"prometheus-community\",\"meta.helm.sh/release-namespace\":\"zerone-monitoring\"},\"creationTimestamp\":\"2023-09-19T16:33:26Z\",\"labels\":{\"app.kubernetes.io/instance\":\"prometheus-community\",\"app.kubernetes.io/managed-by\":\"Helm\",\"app.kubernetes.io/name\":\"alertmanager\",\"app.kubernetes.io/version\":\"v0.26.0\",\"helm.sh/chart\":\"alertmanager-1.6.0\"},\"name\":\"prometheus-community-alertmanager\",\"namespace\":\"zerone-monitoring\",\"resourceVersion\":\"80702\",\"uid\":\"c171403d-1beb-44a0-a39b-b62a7472695f\"}}\n    meta.helm.sh/release-name: prometheus-community\n    meta.helm.sh/release-namespace: zerone-monitoring\n  creationTimestamp: \"2023-09-20T11:06:03Z\"\n  labels:\n    app.kubernetes.io/instance: prometheus-community\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: alertmanager\n    app.kubernetes.io/version: v0.26.0\n    helm.sh/chart: alertmanager-1.6.0\n  name: prometheus-community-alertmanager\n  namespace: zerone-monitoring\n  resourceVersion: \"95493\"\n  uid: c38ca1c3-0c69-48ea-8b3b-be724ab13c90\n</code></pre> <ul> <li>kubectl get cm prometheus\u2013community-server -o yaml</li> </ul> <pre><code>  alerting_rules.yml: |\n    groups:\n    - name: alertname\n      rules:\n      - alert: KubernetesNodeNotReady\n        expr: kube_node_status_condition{condition=\"Ready\",status=\"true\"} == 0\n        for: 10m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes node not ready (instance {{ $labels.instance }})\n          description: \"Node {{ $labels.node }} has been unready for a long time\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesMemoryPressure\n        expr: kube_node_status_condition{condition=\"MemoryPressure\",status=\"true\"} == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes memory pressure (instance {{ $labels.instance }})\n          description: \"{{ $labels.node }} has MemoryPressure condition\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesDiskPressure\n        expr: kube_node_status_condition{condition=\"DiskPressure\",status=\"true\"} == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes disk pressure (instance {{ $labels.instance }})\n          description: \"{{ $labels.node }} has DiskPressure condition\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesNetworkUnavailable\n        expr: kube_node_status_condition{condition=\"NetworkUnavailable\",status=\"true\"} == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes network unavailable (instance {{ $labels.instance }})\n          description: \"{{ $labels.node }} has NetworkUnavailable condition\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesOutOfCapacity\n        expr: sum by (node) ((kube_pod_status_phase{phase=\"Running\"} == 1) + on(uid) group_left(node) (0 * kube_pod_info{pod_template_hash=\"\"})) / sum by (node) (kube_node_status_allocatable{resource=\"pods\"}) * 100 &gt; 90\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes out of capacity (instance {{ $labels.instance }})\n          description: \"{{ $labels.node }} is out of capacity\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesContainerOomKiller\n        expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m &gt;= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\"}[10m]) == 1\n        for: 0m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes container oom killer (instance {{ $labels.instance }})\n          description: \"Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesPersistentvolumeclaimPending\n        expr: kube_persistentvolumeclaim_status_phase{phase=\"Pending\"} == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})\n          description: \"PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesPodCrashLooping\n        expr: increase(kube_pod_container_status_restarts_total[1m]) &gt; 3\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes pod crash looping (instance {{ $labels.instance }})\n          description: \"Pod {{ $labels.pod }} is crash looping\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: ImagePullBackoffAlert\n        expr: kube_pod_container_status_waiting_reason{reason=\"ImagePullBackOff\"} == 1\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} is in ImagePullBackOff state\"\n          description: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} is failing to pull its container image.\"\n</code></pre> <ul> <li>Get the google chat space url </li> </ul> <p></p> <p></p> <ul> <li>Encode  the following to base64.</li> </ul> <pre><code>[app.notification]\n# Jinja2 custom template to print message to GChat.\ncustom_template_path = \"/opt/alertmanager-gchat-integration/cm/notification-template-json.j2\"\n[app.room.lotus(google_space_name)]\nnotification_url = \u2018&lt;google_chat_space_url&gt;\u2019\n</code></pre> <ul> <li>Use the convert base64 code in the Secret (gchat-integration) &amp;&amp; paste  in config.toml section</li> </ul> <pre><code>apiVersion: v1\ndata:\n  config.toml: &lt;Encoded base64 value&gt;&gt;\nkind: Secret\n\n</code></pre> <ul> <li>After updating the Secret and ConfigMap we need to restart some Pod: </li> </ul> <pre><code>    - alert-manager-alertmanager-gchat-integration\n    - prometheus-community-alertmanager\n    - prometheus-community-server\n</code></pre> <p>Output</p> <p></p>"},{"location":"Monitoring/3.%20slack_integration/","title":"Slack Integration","text":"<p>Setup the Prometheus and Grafana</p> <p>Generating the Webhook of the Slack.</p> <p>Go to app and create a new slack notifications webhooks.</p> <p> </p> <ul> <li>kubectl get cm prometheus-community-alertmanager -o yaml</li> </ul> <pre><code> alertmanager.yml: |\n    global:\n      resolve_timeout: 1m\n      slack_api_url: 'https://hooks.slack.com/services/T023XD85BFA/B05XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXG00vrsFjos50iid'\n    route:\n      group_by: ['alertname']\n      group_wait: 10s\n      group_interval: 10s\n      repeat_interval: 1h\n      receiver: 'slack-notifications'\n    receivers:\n    - name: 'slack-notifications'\n      slack_configs:\n      - channel: '#&lt;add here the name of the slack channel&gt;'\n        send_resolved: true\n        icon_url: https://avatars3.githubusercontent.com/u/3380462\n        icon_emoji: ':fire:'\n        title: |-\n          [{{ .Status | toUpper }}{{ if eq .Status \"firing\" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }} for {{ .CommonLabels.job }}\n          {{- if gt (len .CommonLabels) (len .GroupLabels) -}}\n            {{\" \"}}(\n            {{- with .CommonLabels.Remove .GroupLabels.Names }}\n              {{- range $index, $label := .SortedPairs -}}\n                {{ if $index }}, {{ end }}\n                {{- $label.Name }}=\"{{ $label.Value -}}\"\n              {{- end }}\n            {{- end -}}\n            )\n          {{- end }}\n        text: |-\n          {{ range .Alerts -}} *Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}\n          *Description:* {{ .Annotations.description }}\n          *Details:*\n            {{ range .Labels.SortedPairs }} \u2022 *{{ .Name }}:* `{{ .Value }}`\n            {{ end }}\n          {{ end }}\n    templates:\n    - /etc/alertmanager/*.tmpl\n</code></pre> <ul> <li>kubectl get cm prometheus\u2013community-server -o yaml</li> </ul> <pre><code>  alerting_rules.yml: |\n    groups:\n    - name: alertname\n      rules:\n      - alert: KubernetesNodeNotReady\n        expr: kube_node_status_condition{condition=\"Ready\",status=\"true\"} == 0\n        for: 10m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes node not ready (instance {{ $labels.instance }})\n          description: \"Node {{ $labels.node }} has been unready for a long time\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesMemoryPressure\n        expr: kube_node_status_condition{condition=\"MemoryPressure\",status=\"true\"} == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes memory pressure (instance {{ $labels.instance }})\n          description: \"{{ $labels.node }} has MemoryPressure condition\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesDiskPressure\n        expr: kube_node_status_condition{condition=\"DiskPressure\",status=\"true\"} == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes disk pressure (instance {{ $labels.instance }})\n          description: \"{{ $labels.node }} has DiskPressure condition\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesNetworkUnavailable\n        expr: kube_node_status_condition{condition=\"NetworkUnavailable\",status=\"true\"} == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes network unavailable (instance {{ $labels.instance }})\n          description: \"{{ $labels.node }} has NetworkUnavailable condition\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesOutOfCapacity\n        expr: sum by (node) ((kube_pod_status_phase{phase=\"Running\"} == 1) + on(uid) group_left(node) (0 * kube_pod_info{pod_template_hash=\"\"})) / sum by (node) (kube_node_status_allocatable{resource=\"pods\"}) * 100 &gt; 90\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes out of capacity (instance {{ $labels.instance }})\n          description: \"{{ $labels.node }} is out of capacity\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesContainerOomKiller\n        expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m &gt;= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\"}[10m]) == 1\n        for: 0m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes container oom killer (instance {{ $labels.instance }})\n          description: \"Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesPersistentvolumeclaimPending\n        expr: kube_persistentvolumeclaim_status_phase{phase=\"Pending\"} == 1\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})\n          description: \"PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: KubernetesPodCrashLooping\n        expr: increase(kube_pod_container_status_restarts_total[1m]) &gt; 3\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: Kubernetes pod crash looping (instance {{ $labels.instance }})\n          description: \"Pod {{ $labels.pod }} is crash looping\\n  VALUE = {{ $value }}\\n  LABELS = {{ $labels }}\"\n      - alert: ImagePullBackoffAlert\n        expr: kube_pod_container_status_waiting_reason{reason=\"ImagePullBackOff\"} == 1\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} is in ImagePullBackOff state\"\n          description: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} is failing to pull its container image.\"\n\n</code></pre> <ul> <li>After Completing the above steps it shows alerts like below example</li> </ul> <p></p> <ul> <li>For both Gmail and Slack </li> </ul> <pre><code>apiVersion: v1\ndata:\n  alertmanager.yml: |-\n    global:\n      resolve_timeout: 1m\n      slack_api_url: 'https://hooks.slack.com/services/T023XD85BFA/B05XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXG00vrsFjos50iid'\n    route:\n      group_by: ['alertname']\n      group_wait: 10s\n      group_interval: 10s\n      repeat_interval: 1h\n      receiver: 'slack-notifications'\n      routes:\n        # Route for Gmail notifications\n        - receiver: 'gmail-notification'\n          match:\n            severity: 'critical'  # Define the condition to route to Gmail\n          continue: true  # Continue processing other routes\n        # Route for Slack notifications\n        - receiver: 'slack-notifications'\n          match:\n             severity: 'critical'\n          continue: true\n    receivers:\n    - name: 'slack-notifications'\n      slack_configs:\n      - channel: '#lotus'\n        send_resolved: true\n        icon_url: https://avatars3.githubusercontent.com/u/3380462\n        icon_emoji: ':fire:'\n        title: |-\n          [{{ .Status | toUpper }}{{ if eq .Status \"firing\" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }} for {{ .CommonLabels.job }}\n          {{- if gt (len .CommonLabels) (len .GroupLabels) -}}\n            {{ \" \" }}(\n            {{- with .CommonLabels.Remove .GroupLabels.Names }}\n              {{- range $index, $label := .SortedPairs -}}\n                {{ if $index }}, {{ end }}\n                {{- $label.Name }}=\"{{ $label.Value -}}\"\n              {{- end }}\n            {{- end -}}\n            )\n          {{- end }}\n        text: |-\n          {{ range .Alerts -}} *Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}\n          *Description:* {{ .Annotations.description }}\n          *Details:*\n            {{ range .Labels.SortedPairs }} \u2022 *{{ .Name }}:* `{{ .Value }}`\n            {{ end }}\n          {{ end }}\n    - name: 'gmail-notification'\n      webhook_configs:\n      - url: 'http://alert-manager-alertmanager-gchat-integration.zerone-monitoring.svc/alerts?room=lotus'\n    templates:\n    - /etc/alertmanager/*.tmpl\nkind: ConfigMap\nmetadata:\n  annotations:\n    meta.helm.sh/release-name: prometheus-community\n    meta.helm.sh/release-namespace: zerone-monitoring\n  creationTimestamp: \"2023-09-19T16:33:26Z\"\n  labels:\n    app.kubernetes.io/instance: prometheus-community\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: alertmanager\n    app.kubernetes.io/version: v0.26.0\n    helm.sh/chart: alertmanager-1.6.0\n  name: prometheus-community-alertmanager\n  namespace: zerone-monitoring\n  resourceVersion: \"80702\"\n  uid: c171403d-1beb-44a0-a39b-b62a7472695f\n</code></pre> <p>References</p> <pre><code>https://artifacthub.io/packages/helm/prometheus-community/prometheus\nhttps://medium.com/globant/setup-prometheus-and-grafana-monitoring-on-kubernetes-cluster-using-helm-3484efd85891\nhttps://grafana.com/blog/2020/02/25/step-by-step-guide-to-setting-up-prometheus-alertmanager-with-slack-pagerduty-and-gmail/\nhttps://samber.github.io/awesome-prometheus-alerts/rules#kubernetes\n</code></pre>"},{"location":"Security/KubeScape/","title":"KubeScape","text":"<p>Kubescape is an open source Kubernetes security platform for your IDE, CI/CD pipelines, and clusters. Kubescape includes risk analysis, security compliance, and misconfiguration scanning.</p>"},{"location":"Security/KubeScape/#installing-kubescape","title":"Installing Kubescape","text":"<pre><code>curl -s https://raw.githubusercontent.com/kubescape/kubescape/master/install.sh | /bin/bash \n</code></pre> <p>Run a scan</p> <pre><code>kubescape scan --enable-host-scan --verbose\n\n\u2018kubescape scan\u2019 : command to scan k8s clusters\n\u2018--enable-host-scan\u2019:  scan not just the Kubernetes cluster itself, but also the underlying hosts on which the cluster is running.\n\u2018--verbose\u2019: to provide additional information during the scan.\n</code></pre> <p></p> <pre><code>        Figure: Scanning the k8s cluster for Security risk and Vulnerabilities\n</code></pre> <ul> <li> <p>Get results!</p> </li> </ul> <p></p> <pre><code>        Figure: List of Security risk and Vulnerabilities\n</code></pre>"},{"location":"Security/KubeScape/#armosec-with-kubescape","title":"ArmoSec with KubeScape","text":"<ul> <li> <p>Naviagte to cloud.armosec.io/account</p> </li> </ul> <p></p> <ul> <li> <p>Connect the K8s Cluster</p> </li> </ul> <p></p> <p></p> <ul> <li> <p>Check the compliance</p> </li> </ul> <p></p> <ul> <li> <p>Check Dashboard for k8s cluster</p> </li> </ul> <p></p>"},{"location":"Security/KubeScape/#architecture-of-kubescape","title":"Architecture of Kubescape","text":"<p>The main components of the Kubescape architecture are:</p> <ul> <li> <p>Scanner:</p> <p>This is the core component of Kubescape. It scans the Kubernetes cluster and identifies potential security risks and vulnerabilities. It uses different techniques to analyze the Kubernetes configuration and resources, such as identifying misconfigured network policies, insecure container images, and non-compliant Kubernetes objects.</p> </li> <li> <p>Policies: </p> <p>Kubescape uses a set of predefined policies to evaluate the Kubernetes environment. These policies are customizable and can be modified to suit the specific security requirements of an organization. The policies are written in YAML and can be easily extended to include additional checks.</p> </li> <li> <p>Result: </p> <p>The results component of Kubescape provides a detailed report of the security risks and vulnerabilities identified during the scan. It categorizes the findings based on their severity and provides remediation steps for each issue.</p> </li> <li> <p>Web interface: </p> <p>Kubescape comes with a web interface that allows users to interact with the tool and view the scan results. The interface provides an easy-to-use dashboard that summarizes the scan findings and allows users to drill down into specific issues.</p> </li> <li> <p>API:</p> <p>Kubescape also exposes an API that can be used to integrate with other security tools and automate the scanning process. The API can be used to trigger scans, retrieve scan results, and perform other actions programmatically.</p> </li> </ul>"},{"location":"Security/KubeScape/#usage-of-kubescape","title":"Usage of Kubescape","text":"<ul> <li> <p>Security auditing: </p> <p>Kubescape can be used to audit the security of a Kubernetes environment by scanning for security risks and vulnerabilities. It can help security teams to identify potential security issues and take the necessary steps to remediate them.</p> </li> <li> <p>Compliance testing: </p> <p>Kubescape can also be used to test Kubernetes clusters against compliance standards such as PCI-DSS, HIPAA, or SOC 2. It can help organizations to ensure that their Kubernetes environments are compliant with industry standards and regulations.</p> </li> <li> <p>DevOps integration: </p> <p>Kubescape can be integrated into the DevOps pipeline to perform security checks automatically. This can help organizations to ensure that their Kubernetes deployments are secure and compliant before they are deployed.</p> </li> <li> <p>Continuous Monitoring: </p> <p>Kubescape can be used to continuously monitor the security of a Kubernetes environment by running scheduled scans. This can help organizations to detect and remediate security risks and vulnerabilities in a timely manner.</p> </li> </ul>"},{"location":"Security/KubeScape/#demonstration","title":"Demonstration","text":"<p>Installation:</p> <pre><code>curl -s https://raw.githubusercontent.com/kubescape/kubescape/master/install.sh | /bin/bash \n</code></pre> <p></p> <pre><code>kubescape scan  --enable-host-scan\n</code></pre> <p> </p> <pre><code>    Scan the whole cluster in the system\n</code></pre> <ul> <li> <p>Create and Deploy any Kubernetes Deployment file in the cluster</p> </li> </ul> <p></p> <ul> <li> <p>Scan the created deployment file</p> </li> </ul> <pre><code>kubescape scan filename\n</code></pre> <p></p> <pre><code>    Scanning the deployment file with vulnerabilities\n</code></pre> <ul> <li> <p>Solving the Resources Limit vulnerabilities</p> </li> </ul> <p></p> <pre><code>    Adding the limit and request resources inside the deployment yaml file\n</code></pre> <ul> <li> <p>Resources Limit Vulnerabilities problem solved</p> </li> </ul> <p></p> <p>Figure: Resources Limit Vulnerabilities Solved</p> <ul> <li> <p>Uploading the severity in the json format</p> </li> </ul> <pre><code>kubescape scan nginx-deploy.yaml --format json --output op.json\n</code></pre> <p></p> <pre><code>    Saved the op.json file\n</code></pre>"}]}